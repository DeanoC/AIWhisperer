# AI Whisperer Configuration Example
# This file shows an example structure. Create your own 'config.yaml'
# or provide the path to your configuration file via the --config argument.

# --- OpenRouter API Settings --- Required Section ---
openrouter:
  # api_key: "sk-or-v1-abc...xyz" # Recommended: Set the OPENROUTER_API_KEY in a .env file (and ensure .env is in .gitignore) instead of putting your key here.
  model: "google/gemini-2.5-flash-preview" # Required: Specify the model identifier from OpenRouter (e.g., "mistralai/mistral-7b-instruct", "openai/gpt-4o").

  # Optional: Parameters to pass to the OpenRouter API for chat completions.
  # Refer to the specific model's documentation on OpenRouter for available parameters.
  params:
    temperature: 0.7 # Example: Controls randomness (0.0 to 2.0). Higher values = more creative, lower = more deterministic.
    max_tokens: 50000 # Example: Maximum number of tokens to generate in the response.
    # top_p: 1.0
    # frequency_penalty: 0.0
    # presence_penalty: 0.0

  # Optional: Used for identifying your app in OpenRouter logs (sent as headers).
  # Defaults are provided if these are omitted.
  site_url: "http://AIWhisperer:8000" # Example: Your project's URL (sent as HTTP-Referer).
  app_name: "AIWhisperer"           # Example: Your application's name (sent as X-Title).

# --- Prompt Templates --- Required Section ---
prompts: {} # Explicitly set to an empty dictionary

# --- Task-Specific Model Settings ---
task_models:
  "subtask_generator":
    provider: "openrouter"
    model: "google/gemini-2.5-flash-preview"
    params:
      temperature: 0.5
      max_tokens: 8000
  "orchestrator":
    provider: "openrouter"
    model: "google/gemini-2.5-flash-preview"
    params:
      temperature: 0.8
      max_tokens: 16000