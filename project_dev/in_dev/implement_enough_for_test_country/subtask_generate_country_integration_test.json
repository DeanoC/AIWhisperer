{
  "description": "Generate an integration test specifically for the simple_country_test using a real AI connection.",
  "depends_on": [],
  "agent_spec": {
    "type": "test_generation",
    "input_artifacts": [
      "./project_dev/in_dev/implement_enough_for_test_country/implementation_plan.md",
      "./tests/simple_run_test_country/run_test_plan.ps1",
      "./tests/simple_run_test_country/simple_run_test_country_aiwhisperer_config.json",
      "./project_dev/rfc/simple_run_test_country.md"
    ],
    "output_artifacts": [
      "./tests/integration/test_country_runner_integration.py"
    ],
    "instructions": [
      "Create a new Python file at `./tests/integration/test_country_runner_integration.py`.",
      "Import necessary modules, including `pytest` and the AIWhisperer runner function (assuming it's accessible or can be instantiated).",
      "Define a test function within `test_country_runner_integration.py`.",
      "Mark this test function with `pytest.mark.integration` and `pytest.mark.expensive` to ensure it's not run by default.",
      "Inside the test function, configure the AIWhisperer runner to use a real AI backend, likely by setting environment variables or using a test-specific configuration.",
      "Invoke the AIWhisperer runner, passing the path to the simple_run_test_country configuration file (`./tests/simple_run_test_country/simple_run_test_country_aiwhisperer_config.json`).",
      "Implement assertions to verify the successful execution of the country test plan.",
      "Specifically, check for expected outputs or side effects based on the steps defined in `./tests/simple_run_test_country/simple_run_test_country_aiwhisperer_config.json`.",
      "Ensure the test validates that the AI interactions occurred and that the validation steps within the plan passed.",
      "Consider how to handle potential API keys or sensitive information required for the real AI connection (e.g., using environment variables or a separate, untracked config file for testing)."
    ],
    "constraints": [
      "The test must be located in the `./tests/integration/` directory.",
      "The test must use `pytest`.",
      "The test must be marked to run on demand.",
      "The test must use the provided simple_run_test_country configuration file.",
      "The test must verify the end-to-end execution of the plan, including AI interaction and validation steps."
    ],
    "validation_criteria": [
      "./tests/integration/test_country_runner_integration.py exists.",
      "./tests/integration/test_country_runner_integration.py contains a test function.",
      "The test function is marked with `@pytest.mark.integration` and `@pytest.mark.expensive`.",
      "The test function attempts to run the AIWhisperer runner with `./tests/simple_run_test_country/simple_run_test_country_aiwhisperer_config.json`.",
      "The test function includes assertions to check for successful plan execution and validation outcomes."
    ]
  },
  "step_id": "generate_country_integration_test",
  "task_id": "0fa8c553-09fb-45fc-8384-6780cd3c8a02",
  "subtask_id": "d390996b-99b3-4c36-9172-8eea3c0aa05d"
}