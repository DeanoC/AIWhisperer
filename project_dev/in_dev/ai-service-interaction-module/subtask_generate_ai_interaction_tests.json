{
  "description": "Generate unit and integration tests for the AI Service Interaction Module.",
  "depends_on": [],
  "agent_spec": {
    "type": "test_generation",
    "input_artifacts": [
      "project_dev/in_dev/ai-service-interaction-module/ai-service-interaction-module_aiwhisperer_config.json",
      "src/ai_whisperer/openrouter_api.py"
    ],
    "output_artifacts": [
      "tests/unit/test_ai_service_interaction.py",
      "tests/integration/test_ai_service_interaction_integration.py"
    ],
    "instructions": [
      "Analyze the provided design document ('project_dev/in_dev/ai-service-interaction-module/ai-service-interaction-module_aiwhisperer_config.json') and the implementation ('src/ai_whisperer/openrouter_api.py') to understand the AI service interaction logic.",
      "Create a new Python file at 'tests/unit/test_ai_service_interaction.py'.",
      "Inside 'tests/unit/test_ai_service_interaction.py', write unit tests covering the following aspects:",
      "- Verify correct handling of API key authentication, including cases with valid and invalid keys.",
      "- Test the formatting of requests sent to the AI service, ensuring headers, payload, and parameters are correctly constructed.",
      "- Write tests for handling standard (non-streaming) responses, confirming data extraction and error handling.",
      "- Implement tests for streaming responses, focusing on parsing individual chunks, handling delimiters, and correctly identifying the end of the stream.",
      "Create a new Python file at 'tests/integration/test_ai_service_interaction_integration.py'.",
      "Inside 'tests/integration/test_ai_service_interaction_integration.py', write integration tests:",
      "- Test the initialization of the AI service interaction module with configuration from the AIWhisperer system.",
      "- Write a test case to simulate sending a prompt and receiving a standard response, using mocks for the external API call.",
      "- Implement a test case to simulate the end-to-end flow of sending a prompt and handling a streaming response, using mocks to simulate the streamed chunks.",
      "- Include test cases for common error conditions such as invalid API keys, simulated network errors, and service-side errors (e.g., 4xx or 5xx responses).",
      "Ensure all tests are well-structured, readable, and follow standard Python testing practices (e.g., using `unittest` or `pytest`).",
      "Add necessary imports and setup/teardown methods where required."
    ],
    "constraints": [
      "Use mocking libraries (like `unittest.mock` or `pytest-mock`) extensively to isolate the tests from actual external API calls.",
      "Do not make actual HTTP requests to the OpenRouter API or any other external service during test execution.",
      "Focus strictly on testing the logic within the AI Service Interaction Module itself.",
      "Ensure test files are placed in the specified output artifact paths."
    ],
    "validation_criteria": [
      "The file 'tests/unit/test_ai_service_interaction.py' must exist.",
      "The file 'tests/integration/test_ai_service_interaction_integration.py' must exist.",
      "'tests/unit/test_ai_service_interaction.py' must contain tests specifically for authentication, request formatting, standard responses, and streaming responses.",
      "'tests/integration/test_ai_service_interaction_integration.py' must contain tests covering module initialization and end-to-end (mocked) request/response flows for both standard and streaming scenarios.",
      "Both test files must include test cases for handling error conditions.",
      "Tests should demonstrate the use of mocking to avoid external dependencies."
    ]
  },
  "step_id": "generate_ai_interaction_tests",
  "task_id": "525d04d4-42c9-4a08-ac2b-9461936ab13b",
  "subtask_id": "4a11bb76-7e33-4578-9e92-cb53f455341d"
}