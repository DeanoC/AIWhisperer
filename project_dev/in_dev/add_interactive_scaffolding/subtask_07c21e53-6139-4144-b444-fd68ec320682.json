{
  "description": "Implement the interactive prompt for the list-models feature.",
  "instructions": [
    "Locate the `list_models_command` function within `ai_whisperer/commands.py`.",
    "Modify the `list_models_command` function to include logic for an interactive mode. This mode should be triggered by a new command-line option (e.g., `--interactive`).",
    "Inside the interactive mode logic in `ai_whisperer/commands.py`, instantiate the appropriate interactive delegate from `monitor/interactive_delegate.py`.",
    "Implement an interactive loop within the `list_models_command` function when in interactive mode. This loop should:",
    "Prompt the user for input using the instantiated interactive delegate.",
    "Send the user's input to the AI service interaction logic in `ai_whisperer/ai_service_interaction.py`.",
    "Receive the AI's response from the AI service interaction logic.",
    "Display the AI's response to the user using the interactive delegate.",
    "Continue the loop until the user enters a specific command to quit (e.g., 'quit', 'exit').",
    "Add necessary methods to `monitor/interactive_delegate.py` to facilitate prompting for user input and displaying AI responses. Consider methods like `get_user_input()` and `display_ai_response(response)`.",
    "Modify the AI service interaction logic in `ai_whisperer/ai_service_interaction.py` to accept user queries from the interactive delegate and return AI responses.",
    "Ensure that the integration between `ai_whisperer/commands.py`, `monitor/interactive_delegate.py`, and `ai_whisperer/ai_service_interaction.py` correctly passes user input and AI output.",
    "Run the integration tests located in `tests/integration/test_list_models_interactive.py`. Debug and fix any failures until all tests pass.",
    "Review the existing `list-models` command implementation in `ai_whisperer/commands.py` and its associated test `tests/test_list_models_command.py` to understand the current structure and how to best integrate the interactive feature."
  ],
  "input_artifacts": [
    "docs/list_models_interaction_analysis.md",
    "tests/integration/test_list_models_interactive.py",
    "ai_whisperer/commands.py",
    "monitor/interactive_delegate.py",
    "ai_whisperer/ai_service_interaction.py",
    "tests/test_list_models_command.py"
  ],
  "output_artifacts": [
    "ai_whisperer/commands.py",
    "monitor/interactive_delegate.py",
    "ai_whisperer/ai_service_interaction.py"
  ],
  "constraints": [
    "The interactive functionality for the list-models command must exclusively use the delegate system for user interaction and displaying output.",
    "The implemented interactive loop must be capable of receiving user input and displaying AI output received from the AI service.",
    "All tests defined in `tests/integration/test_list_models_interactive.py` must pass successfully after the implementation."
  ],
  "validation_criteria": [
    "Executing the `list-models` command with the interactive option successfully starts an interactive prompt in the terminal.",
    "Typing a message into the interactive prompt and pressing Enter results in that input being sent to the AI service via the delegate.",
    "When the AI service returns a response, that response is correctly displayed in the terminal via the delegate.",
    "Entering a designated quit command (e.g., 'quit') terminates the interactive loop and the command execution.",
    "All tests within the `tests/integration/test_list_models_interactive.py` file execute without errors and pass."
  ],
  "type": "file_edit",
  "name": "implement_list_models_interaction",
  "depends_on": [
    "test_list_models_interaction_generation"
  ],
  "task_id": "32fb08e9-d83b-4027-bdc5-ed57c1604243",
  "subtask_id": "07c21e53-6139-4144-b444-fd68ec320682"
}